# Manus Any-to-Any Omni Model

Production-ready any-to-any multimodal model with DFM connectors, optimized training suite, and comprehensive dataset support.

## ğŸš€ Quick Start

### 1. Test Setup (10 min)

```bash
cd training-suite
./train_1K_ultra.sh
```

### 2. Development (3 hours)

```bash
cd training-suite
./train_100K_ultra.sh
```

### 3. Production (6 days)

```bash
cd training-suite
./train_5M_ultra.sh
```

## ğŸ“ Project Structure

```
manus_model/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ multimodal/              # Multimodal components
â”‚   â”‚   â”œâ”€â”€ model.py             # OmniMultimodalLM (DFM-powered)
â”‚   â”‚   â”œâ”€â”€ connectors/          # DFM & Perceiver connectors
â”‚   â”‚   â””â”€â”€ datasets/            # Dataset loaders
â”‚   â”œâ”€â”€ utils/                   # Utilities
â”‚   â”œâ”€â”€ 24_multimodal_training.py # Main training script
â”‚   â””â”€â”€ process_manual_datasets.py
â”œâ”€â”€ training-suite/              # 18 training scripts
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ train_1K_ultra.sh       # Fast test
â”‚   â”œâ”€â”€ train_5M_ultra.sh       # Production (recommended)
â”‚   â””â”€â”€ train_FULL_ultra.sh     # Complete dataset
â”œâ”€â”€ config/                      # Training configurations
â”‚   â”œâ”€â”€ training_config.yaml
â”‚   â”œâ”€â”€ ds_config.json          # DeepSpeed ZeRO-2
â”‚   â””â”€â”€ ds_config_ultra.json    # DeepSpeed ZeRO-3
â”œâ”€â”€ base-model/                 # Model weights
â”‚   â”œâ”€â”€ gpt-oss-20b/
â”‚   â”œâ”€â”€ siglip2-so400m-patch16-512/
â”‚   â”œâ”€â”€ whisper-large-v3-turbo/
â”‚   â”œâ”€â”€ PaDT_OVD_3B/
â”‚   â””â”€â”€ parakeet-tdt-0.6b-v3/
â”œâ”€â”€ results/                    # Training results CSV
â””â”€â”€ logs/                       # Training logs

## ğŸ¯ Features

- **True Any-to-Any**: Image â†’ Video, Audio â†’ Text, etc.
- **DFM Connectors**: SOTA discrete flow matching (5-10% gains)
- **Ultra-Optimized**: 6x faster training (4-bit, ZeRO-3)
- **100M+ Samples**: E-MM1 + 10 manual datasets
- **Memory Efficient**: Fits 16GB VRAM + 32GB RAM
- **Auto Train/Val/Test**: 80/10/10 splits automatic

## ï¿½ Pipeline Usage

The project uses two master shell scripts to handle the entire lifecycle.

### 1. Multimodal Pipeline (Vision/Audio/Video)

Use this for training the Omni-Modal model (Connectors, Projectors, Full Fine-tuning).

```bash
./run_multimodal_pipeline.sh [PHASE] [OPTIONS]
```

**Phases:**

- `download`: Download raw datasets (Script 22).
- `distill`: Run teacher distillation (Script 23).
- `train`: Run training loop (Script 24).
- `all`: Run full sequence (**Default**).

**Options (Flags)**

| Flag | Description | Valid Values | Default |
| :--- | :--- | :--- | :--- |
| `--modality` | Data type to process | `vision`, `audio`, `video` | `vision` |
| `--stage` | Training configuration | `1` (Projectors), `2` (Full Model) | `1` |
| `--sample-size` | **Limit samples per dataset** | Any Integer (e.g. `50`) | `0` (All) |
| `--limit` | Download limit (HuggingFace) | Any Integer | `1000` |
| `--teacher` | Teacher model for labelling | `mock-teacher`, `gpt-4v` | `mock-teacher` |

**Example:**

```bash
# Train Stage 1 with only 50 samples per dataset (Fast Test)
./run_multimodal_pipeline.sh train --stage=1 --sample-size=50
```

### 2. Text/Code Pipeline (SFT/RLHF)

Use this for standard LLM fine-tuning (Text, Code, Reasoning).

```bash
./run_pipeline.sh [PHASE] [OPTIONS]
```

**Phases:** `download`, `process`, `validate`, `train`, `all`.

**Options (Flags)**

| Flag | Description | Valid Values | Default |
| :--- | :--- | :--- | :--- |
| `--mode` | Safety alignment mode | `censored`, `uncensored` | `censored` |
| `--sample-size` | Download limit | Any Integer | `200000` |
| `--target-samples` | Premium data limit | Any Integer | `100000` |

## ğŸ›  Setup

```bash
conda activate manus
pip install -r requirements.txt
```

## ğŸ“ˆ Results

All experiments logged to `results/training_results.csv`:

- Training/val/test losses
- VRAM/RAM usage
- Training time
- Throughput

View results:

```bash
cat results/training_results.csv
```

## ğŸ— Architecture

- **LLM**: GPT-OSS-20B (13GB, 4-bit quantized)
- **Vision**: SigLIP2 â†’ DFM Connector
- **Audio**: Whisper V3 â†’ DFM Connector
- **Video Decoder**: PaDT_OVD_3B
- **Speech Decoder**: Parakeet-TDT
- **Optimization**: DeepSpeed ZeRO-3, 4-bit QLoRA

## ğŸ“š Documentation

See `training-suite/README.md` for detailed usage.

## âœ… Ready to Train
