# Nexus: Universal Modular AI

![Nexus Badge](https://img.shields.io/badge/Status-Stage_6_Release-success) ![License](https://img.shields.io/badge/License-MIT-blue)

**Nexus** is a unified, modular AI ecosystem that distills the capabilities of **15 specialized "Teacher" models** into a single, efficient "Student" architecture. By leveraging advanced **Activation Anchoring (protected subspaces)** and Sparse Intent Routing, Nexus delivers state-of-the-art performance across text, vision, audio, and videoâ€”with **100% teacher-free inference**.

> **Zero Retention Loss Guarantee:** Nexus is engineered to maintain >95% of the original teacher performance on critical benchmarks without requiring any teacher weights at runtime.

---

## ğŸ† Capability Tier Declaration
Nexus provides a tier-based capability manifest so consumers can understand the fidelity and resource requirements:
- **Tier 1 (Core):** General Language, Reasoning, Base NLP. (Optimized for <8GB VRAM, Teacher-Free)
- **Tier 2 (Pro):** Code, Tool-Use, Agent Planning. (Optimized for <12GB VRAM, Rank 512, Teacher-Free)
- **Tier 3 (Ultra):** Voice Cloning, Vision QA, Video. (Optimized for 16GB VRAM, Rank 1024, Teacher-Free)

---

## ğŸš€ Key Features

*   **Universal Perception**: Native understanding of Text, Images, Audio (Speech/Music), and Video.
*   **Modular Architecture**: Hot-swappable **Adapters** allow you to load only the capabilities you need (e.g., enable `VisionAdapter` for image tasks).
*   **15-Teacher Distillation**: Knowledge from industry leaders (Gemini, Qwen, Stable Diffusion, Whisper) fused into one.
*   **Efficient Inference**: Optimized for consumer hardware (RTX 3090/4090/5080) with NF4 quantization.

---

## ğŸ“¦ Installation

```bash
pip install nexus-ai
```

## âš¡ Quick Start

```python
import nexus

# Load the student with specific adapters
model = nexus.load(
    "nexus-student-v1",
    adapters=["vision", "reasoning", "audio"]
)

# Multi-modal input (Text + Image)
response = model.generate(
    input="Analyze this dashboard and explain the trend.",
    image="dashboard.png",
    audio=None
)

print(response)
# Output: "The dashboard shows a 15% increase in user retention..."
```

---

## ğŸ§  The Ecosystem (Teacher Models)

Nexus is trained on the distilled knowledge of these 14 specialized models:

| Category | Teacher Model | Capability |
| :--- | :--- | :--- |
| **Reasoning & Agents** | AgentCPM-Explore | Long-horizon Planning |
| **Language** | Gemma Scope 27B / GLM-4.7 Flash | General NLP & Coding |
| **Vision-Language** | Step3-VL-10B | Visual QA & Reasoning |
| **Audio (ASR)** | VibeVoice-ASR / Parakeet | Long-form & Multilingual Speech-to-Text |
| **Audio (Gen)** | Personaplex / Qwen3-TTS | Conversational Voice & cloning |
| **Visual Gen** | Stable Diffusion 3 / SVD | Image & Video Generation |
| **Encoders** | SigLIP / VideoMAE | Dense Visual Understanding |

---

## ğŸ”§ Architecture

Nexus uses a **Sparse Intent Router** to dynamically activate the relevant sub-modules (Adapters) based on the input query. This ensures that you only pay the compute cost for the modalities you use.

*   **Core**: 4B Parameter Transformer (Student)
*   **Router**: Lightweight MLP for intent classification
*   **Adapters**: Specialized LoRA-based modules for each modality

## ğŸ“œ License

This project is licensed under the MIT License.
