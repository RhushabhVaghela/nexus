base_model:
  name: "/mnt/e/data/models/Qwen2.5-Omni-7B-GPTQ-Int4"
  torch_dtype: "float16"
  trust_remote_code: true

lora:
  enabled: true
  rank: 64
  alpha: 128
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

training:
  learning_rate: 2.0e-4
  num_epochs: 3
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  max_seq_length: 32768
  bf16: true
  logging_steps: 1
  save_steps: 100

data:
  mixed_data_dir: "/mnt/e/data/downloaded"

output:
  dir: "/mnt/e/models/manus-prime-sft"

wandb:
  enabled: false
  project: "manus-prime"
