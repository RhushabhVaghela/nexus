"""
Comprehensive Unit Tests for Pre-distillation Memorization Classifier (Paper 2601.15394).

Tests cover:
- Feature extraction (entropy, perplexity, KLD)
- Logistic regression training
- Prediction accuracy
- Model save/load
- Edge cases (empty input, None values)
"""

import pytest
import numpy as np
import sys
import os
import pickle
from unittest.mock import Mock, MagicMock, patch

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..'))

from src.nexus_final.auditor import (
    MemorizationClassifier,
    MemorizationAuditor,
    DistillationReport
)


class TestMemorizationClassifierInitialization:
    """Test suite for classifier initialization."""
    
    def test_default_initialization(self):
        """Test classifier initializes with correct defaults."""
        classifier = MemorizationClassifier()
        assert classifier.model is None
        assert classifier.scaler is None
        assert not classifier.is_trained
        assert classifier.target_auc_roc == 0.9997
        assert classifier.model_path is None
    
    def test_initialization_with_model_path(self, tmp_path):
        """Test classifier initializes with model path."""
        model_path = str(tmp_path / "test_model.pkl")
        # Create a dummy model file
        dummy_data = {
            'model': None,
            'scaler': None,
            'is_trained': False,
            'target_auc_roc': 0.9997
        }
        with open(model_path, 'wb') as f:
            pickle.dump(dummy_data, f)
        
        classifier = MemorizationClassifier(model_path)
        assert classifier.model_path == model_path
    
    def test_initialization_with_nonexistent_path(self):
        """Test classifier handles non-existent model path gracefully."""
        classifier = MemorizationClassifier("/nonexistent/path/model.pkl")
        assert classifier.model is None
        assert not classifier.is_trained


class TestFeatureExtraction:
    """Test feature extraction methods."""
    
    def test_calculate_zlib_entropy_random_text(self):
        """Test entropy calculation for random text."""
        # Random text should have high entropy
        random_text = "aslkdjfalskjdflkasjdflkasjdflkasjd"
        entropy = MemorizationClassifier.calculate_zlib_entropy(random_text)
        assert entropy > 0
        assert isinstance(entropy, float)
    
    def test_calculate_zlib_entropy_repetitive_text(self):
        """Test entropy calculation for repetitive text."""
        # Repetitive text should have lower entropy
        repetitive_text = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"
        entropy = MemorizationClassifier.calculate_zlib_entropy(repetitive_text)
        assert entropy > 0
        
        # Compare with random text
        random_text = "aslkdjfalskjdflkasjdflkasjdflkasjd"
        random_entropy = MemorizationClassifier.calculate_zlib_entropy(random_text)
        assert entropy < random_entropy
    
    def test_calculate_zlib_entropy_empty_string(self):
        """Test entropy calculation for empty string."""
        entropy = MemorizationClassifier.calculate_zlib_entropy("")
        assert entropy == 0.0
    
    def test_calculate_zlib_entropy_single_char(self):
        """Test entropy calculation for single character."""
        entropy = MemorizationClassifier.calculate_zlib_entropy("a")
        assert entropy >= 0.0
    
    def test_extract_features_mock(self, mocker):
        """Test feature extraction with mocked models."""
        # Create mock objects
        mock_tokenizer = mocker.MagicMock()
        mock_tokenizer.return_value = {
            "input_ids": MagicMock(),
        }
        mock_tokenizer.pad_token_id = 0
        mock_tokenizer.eos_token_id = 1
        
        mock_teacher = mocker.MagicMock()
        mock_teacher_outputs = mocker.MagicMock()
        mock_teacher_outputs.loss.item.return_value = 2.0  # perplexity ~7.4
        mock_teacher_outputs.logits = MagicMock()
        mock_teacher.return_value = mock_teacher_outputs
        
        mock_baseline = mocker.MagicMock()
        mock_baseline_outputs = mocker.MagicMock()
        mock_baseline_outputs.loss.item.return_value = 3.0  # perplexity ~20.1
        mock_baseline_outputs.logits = MagicMock()
        mock_baseline.return_value = mock_baseline_outputs
        
        # Patch torch.softmax and torch.log_softmax
        with patch('torch.softmax') as mock_softmax, \
             patch('torch.log_softmax') as mock_log_softmax:
            mock_probs = MagicMock()
            mock_log_probs = MagicMock()
            mock_softmax.return_value = mock_probs
            mock_log_softmax.return_value = mock_log_probs
            
            classifier = MemorizationClassifier()
            # Note: extract_features requires actual torch tensors, so we test the structure
            assert classifier is not None
    
    def test_extract_features_without_tokenizer(self):
        """Test that feature extraction raises error without tokenizer."""
        classifier = MemorizationClassifier()
        mock_teacher = MagicMock()
        
        with pytest.raises(ValueError, match="Tokenizer is required"):
            classifier.extract_features(
                text="Test text",
                teacher_model=mock_teacher,
                tokenizer=None
            )


class TestLogisticRegressionTraining:
    """Test logistic regression training functionality."""
    
    def test_untrained_prediction_error(self):
        """Test that predicting before training raises error."""
        classifier = MemorizationClassifier()
        
        with pytest.raises(RuntimeError, match="Classifier must be trained"):
            classifier.predict(np.array([0.5, 1.0, 0.8, 0.2]))
        
        with pytest.raises(RuntimeError, match="Classifier must be trained"):
            classifier.predict_proba(np.array([0.5, 1.0, 0.8, 0.2]))
    
    def test_model_save_and_load(self, tmp_path):
        """Test model save and load functionality."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        
        # Create a mock trained state
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[0.5, 0.3, 0.2, 0.1]])
        classifier.model.intercept_ = np.array([0.0])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.0, 0.0, 0.0, 0.0])
        classifier.scaler.scale_ = np.array([1.0, 1.0, 1.0, 1.0])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # Save the model
        save_path = tmp_path / "test_classifier.pkl"
        classifier.save(str(save_path))
        
        # Verify file exists
        assert save_path.exists()
        
        # Load the model
        loaded_classifier = MemorizationClassifier(str(save_path))
        
        # Verify loaded state
        assert loaded_classifier.is_trained
        assert loaded_classifier.model is not None
        assert loaded_classifier.scaler is not None
        assert loaded_classifier.target_auc_roc == 0.9997
    
    def test_predict_after_training(self):
        """Test prediction after training simulation."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        
        # Create a simple mock model
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[1.0, -0.5, 0.3, -0.2]])
        classifier.model.intercept_ = np.array([0.1])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.5, 10.0, 5.0, 0.1])
        classifier.scaler.scale_ = np.array([0.1, 2.0, 1.0, 0.05])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # Test prediction
        features = np.array([0.6, 12.0, 6.0, 0.15])
        prediction = classifier.predict(features)
        
        # Should return 0 or 1
        assert prediction in [0, 1]
        
        # Test probability prediction
        proba = classifier.predict_proba(features)
        assert len(proba) == 2
        assert abs(sum(proba) - 1.0) < 0.001  # Probabilities should sum to 1


class TestPredictionAccuracy:
    """Test prediction accuracy scenarios."""
    
    def test_high_entropy_prediction(self, mocker):
        """Test prediction for high entropy (non-memorized) text."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        
        # Create a model that predicts non-memorized (class 0) for high entropy
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[-10.0, -0.1, -0.1, -0.1]])  # Negative weights favor class 0
        classifier.model.intercept_ = np.array([5.0])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.5, 10.0, 5.0, 0.1])
        classifier.scaler.scale_ = np.array([0.1, 2.0, 1.0, 0.05])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # High entropy features
        features = np.array([0.9, 50.0, 45.0, 0.5])
        prediction = classifier.predict(features)
        proba = classifier.predict_proba(features)
        
        assert prediction == 0  # Should predict non-memorized
        assert proba[0] > proba[1]  # Higher probability for class 0
    
    def test_low_entropy_prediction(self, mocker):
        """Test prediction for low entropy (potentially memorized) text."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        
        # Create a model that predicts memorized (class 1) for low entropy
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[15.0, 0.05, 0.05, 0.05]])  # Positive weights favor class 1
        classifier.model.intercept_ = np.array([-5.0])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.5, 10.0, 5.0, 0.1])
        classifier.scaler.scale_ = np.array([0.1, 2.0, 1.0, 0.05])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # Low entropy features (potentially memorized)
        features = np.array([0.1, 5.0, 4.5, 0.01])
        prediction = classifier.predict(features)
        proba = classifier.predict_proba(features)
        
        assert prediction == 1  # Should predict memorized
        assert proba[1] > proba[0]  # Higher probability for class 1


class TestEdgeCases:
    """Test edge cases and error handling."""
    
    def test_empty_input_entropy(self):
        """Test handling of empty input for entropy."""
        entropy = MemorizationClassifier.calculate_zlib_entropy("")
        assert entropy == 0.0
    
    def test_none_input_handling(self):
        """Test handling of None values."""
        # Entropy calculation with None should be handled gracefully
        with pytest.raises((AttributeError, TypeError)):
            MemorizationClassifier.calculate_zlib_entropy(None)
    
    def test_very_long_text_entropy(self):
        """Test entropy calculation for very long text."""
        long_text = "a" * 10000
        entropy = MemorizationClassifier.calculate_zlib_entropy(long_text)
        assert entropy >= 0.0
        assert entropy <= 1.0  # Normalized entropy should be in [0, 1]
    
    def test_unicode_text_entropy(self):
        """Test entropy calculation with unicode characters."""
        unicode_text = "Hello ä¸–ç•Œ ðŸŒ Ã©mojis: ðŸš€ðŸ”¥ðŸ’¯"
        entropy = MemorizationClassifier.calculate_zlib_entropy(unicode_text)
        assert entropy > 0
    
    def test_special_characters_entropy(self):
        """Test entropy calculation with special characters."""
        special_text = "!@#$%^&*()_+-=[]{}|;':\",./<>?"
        entropy = MemorizationClassifier.calculate_zlib_entropy(special_text)
        assert entropy > 0
    
    def test_predict_with_invalid_features(self):
        """Test prediction with invalid feature dimensions."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[0.5, 0.3, 0.2, 0.1]])  # Expects 4 features
        classifier.model.intercept_ = np.array([0.0])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.0, 0.0, 0.0, 0.0])
        classifier.scaler.scale_ = np.array([1.0, 1.0, 1.0, 1.0])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # Wrong number of features - should raise error
        with pytest.raises((ValueError, RuntimeError)):
            classifier.predict(np.array([0.5]))  # Only 1 feature instead of 4


class TestMemorizationAuditor:
    """Test suite for MemorizationAuditor."""
    
    def test_auditor_initialization(self, mocker):
        """Test auditor initialization."""
        mock_tokenizer = mocker.MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer, prefix_len=50, suffix_len=50)
        
        assert auditor.tokenizer == mock_tokenizer
        assert auditor.prefix_len == 50
        assert auditor.suffix_len == 50
        assert auditor.classifier is not None
    
    def test_calculate_zlib_entropy(self):
        """Test static entropy calculation method."""
        text = "This is a test text for entropy calculation."
        entropy = MemorizationAuditor.calculate_zlib_entropy(text)
        assert entropy > 0
        
        # Empty text
        empty_entropy = MemorizationAuditor.calculate_zlib_entropy("")
        assert empty_entropy == 0.0
    
    def test_calculate_match_ratio_perfect(self):
        """Test match ratio calculation - perfect match."""
        mock_tokenizer = MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer)
        
        ratio = auditor._calculate_match_ratio([1, 2, 3, 4, 5], [1, 2, 3, 4, 5])
        assert ratio == 1.0
    
    def test_calculate_match_ratio_partial(self):
        """Test match ratio calculation - partial match."""
        mock_tokenizer = MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer)
        
        ratio = auditor._calculate_match_ratio([1, 2, 4, 5, 6], [1, 2, 3, 4, 5])
        assert ratio == 2/5  # 2 matches out of 5
    
    def test_calculate_match_ratio_no_match(self):
        """Test match ratio calculation - no match."""
        mock_tokenizer = MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer)
        
        ratio = auditor._calculate_match_ratio([10, 20, 30], [1, 2, 3])
        assert ratio == 0.0
    
    def test_calculate_match_ratio_empty_target(self):
        """Test match ratio calculation - empty target."""
        mock_tokenizer = MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer)
        
        ratio = auditor._calculate_match_ratio([1, 2, 3], [])
        assert ratio == 0.0
    
    def test_calculate_match_ratio_empty_generated(self):
        """Test match ratio calculation - empty generated."""
        mock_tokenizer = MagicMock()
        auditor = MemorizationAuditor(mock_tokenizer)
        
        ratio = auditor._calculate_match_ratio([], [1, 2, 3])
        assert ratio == 0.0


class TestDistillationReport:
    """Test suite for DistillationReport."""
    
    def test_report_creation(self):
        """Test creating a distillation report."""
        report = DistillationReport(
            hard_distillation_rate=0.15,
            soft_distillation_rate=0.08,
            inherited_from_teacher_rate=0.12,
            privacy_recommendation="SOFT_DISTILLATION_RECOMMENDED",
            detailed_metrics={"samples_analyzed": 100}
        )
        
        assert report.hard_distillation_rate == 0.15
        assert report.soft_distillation_rate == 0.08
        assert report.inherited_from_teacher_rate == 0.12
        assert report.privacy_recommendation == "SOFT_DISTILLATION_RECOMMENDED"
        assert report.detailed_metrics["samples_analyzed"] == 100
    
    def test_report_with_zero_rates(self):
        """Test report with zero memorization rates."""
        report = DistillationReport(
            hard_distillation_rate=0.0,
            soft_distillation_rate=0.0,
            inherited_from_teacher_rate=0.0,
            privacy_recommendation="BOTH_METHODS_ACCEPTABLE",
            detailed_metrics={}
        )
        
        assert report.hard_distillation_rate == 0.0
        assert report.soft_distillation_rate == 0.0
    
    def test_report_with_high_rates(self):
        """Test report with high memorization rates."""
        report = DistillationReport(
            hard_distillation_rate=0.95,
            soft_distillation_rate=0.85,
            inherited_from_teacher_rate=0.90,
            privacy_recommendation="ADDITIONAL_PRIVACY_SAFEGUARDS_NEEDED",
            detailed_metrics={"samples_analyzed": 1000}
        )
        
        assert report.hard_distillation_rate == 0.95
        assert report.privacy_recommendation == "ADDITIONAL_PRIVACY_SAFEGUARDS_NEEDED"


class TestPerformanceBenchmarks:
    """Performance benchmarks for classifier operations."""
    
    @pytest.mark.benchmark
    def test_entropy_calculation_performance(self, benchmark):
        """Benchmark entropy calculation performance."""
        text = "This is a sample text for benchmarking entropy calculation performance." * 100
        result = benchmark(MemorizationClassifier.calculate_zlib_entropy, text)
        assert result >= 0
    
    def test_prediction_performance(self):
        """Test prediction performance with timing."""
        import time
        from sklearn.linear_model import LogisticRegression
        from sklearn.preprocessing import StandardScaler
        
        classifier = MemorizationClassifier()
        classifier.model = LogisticRegression()
        classifier.model.classes_ = np.array([0, 1])
        classifier.model.coef_ = np.array([[0.5, 0.3, 0.2, 0.1]])
        classifier.model.intercept_ = np.array([0.0])
        
        classifier.scaler = StandardScaler()
        classifier.scaler.mean_ = np.array([0.0, 0.0, 0.0, 0.0])
        classifier.scaler.scale_ = np.array([1.0, 1.0, 1.0, 1.0])
        classifier.scaler.n_features_in_ = 4
        
        classifier.is_trained = True
        
        # Time 1000 predictions
        features = np.array([0.5, 1.0, 0.8, 0.2])
        start = time.time()
        for _ in range(1000):
            classifier.predict(features)
        elapsed = time.time() - start
        
        # Should complete 1000 predictions in reasonable time
        assert elapsed < 1.0  # Less than 1 second


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
